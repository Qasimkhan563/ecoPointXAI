
# ğŸŒ³ ecoPointXAI â€” Explainable 3D Forest Intelligence

[![R-CMD-check](https://github.com/Qasimkhan563/ecoPointXAI/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/Qasimkhan563/ecoPointXAI/actions)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![GitHub release](https://img.shields.io/github/v/release/Qasimkhan563/ecoPointXAI?include_prereleases)](https://github.com/Qasimkhan563/ecoPointXAI/releases)
[![Made with R](https://img.shields.io/badge/Made%20with-R-blue.svg)](https://cran.r-project.org/)

---

### ğŸŒ² **ecoPointXAI** provides an *explainable 3D forest analytics pipeline* for LiDAR point clouds.  
It bridges **3D deep learning (PointNet)**, **ecological feature engineering**, and **explainable AI (XAI)** techniques â€” making it possible to model, visualize, and interpret forest canopy structure transparently.

---

## âœ¨ Key Features

âœ… **Voxelization & Preprocessing** â€” Convert raw LiDAR point clouds into structured 3D voxel grids.  
ğŸŒ¿ **Ecological Metrics** â€” Derive canopy height, cover, and structural complexity indicators.  
ğŸ§  **Deep Learning (PointNet)** â€” Train explainable 3D neural models directly on point clouds.  
ğŸ” **Explainability** â€” Use SHAP or gradient-based attributions to understand model reasoning.  
ğŸ¨ **Visualization Tools** â€” Render interactive 3D terrain, canopy metrics, and feature importance.

---

## ğŸ§© Installation

You can install the **development version** from GitHub:

```r
# install.packages("devtools")
devtools::install_github("Qasimkhan563/ecoPointXAI")

library(ecoPointXAI)
```

---

## ğŸš€ Quick Example

```r
library(ecoPointXAI)

# 1ï¸âƒ£ Load and voxelize a sample LiDAR point cloud
las_path <- system.file("extdata", "forest_plot_small.laz", package = "ecoPointXAI")
vox <- preprocess_voxelize(las_path, voxel_size = 1)

# 2ï¸âƒ£ Compute ecological canopy metrics
metrics <- compute_ecological_metrics(vox)

# 3ï¸âƒ£ Train a lightweight PointNet model
model <- pointnet_model(num_features = 3, num_classes = 2)

# 4ï¸âƒ£ Generate explainability outputs
exp <- explain_pointnet(model, vox, method = "gradients")

# 5ï¸âƒ£ Visualize feature importance
visualize_explainability(exp)
```

---

## ğŸ“˜ Documentation

Full vignette and examples are available in:

```r
vignette("ecoPointXAI_intro")
```

or visit the [ğŸ“– GitHub Wiki](https://github.com/Qasimkhan563/ecoPointXAI/wiki) for extended tutorials.

---

## ğŸ¤ Citation

If you use **ecoPointXAI** in your research, please cite:

> Muhammad Qasim (2025). *ecoPointXAI: Explainable 3D Forest Analytics with PointNet and LiDAR.*  
> R package version 0.0.1.  
> Available at: <https://github.com/Qasimkhan563/ecoPointXAI>

---

## ğŸ§  Why ecoPointXAI?

ğŸŒ Traditional 2D raster workflows overlook the 3D structure of forests.  
**ecoPointXAI** brings explainable deep learning into 3D space â€” allowing scientists to *see why* their models behave as they do, improving interpretability, transparency, and ecological relevance.

---

## ğŸ› ï¸ Development Notes

- Built and tested under **R 4.4.x**
- Large example LiDAR file reduced to **<3 MB** for CRAN safety
- Heavy tests and examples are wrapped with `skip_on_cran()`
- Compatible with Linux, macOS, and Windows

---

### ğŸ§© Maintainer
**Muhammad Qasim** â€“ [@Qasimkhan563](https://github.com/Qasimkhan563)  
ğŸ“§ *for research inquiries and collaboration, please contact via GitHub Issues or Discussions.*

---

> _ecoPointXAI: Explainable 3D Forest Intelligence for LiDAR-based Ecological Insights._
